{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termination_msg(msg):\n",
    "        content = msg.get(\"content\")\n",
    "        if content.lower() in (\"exit\", \"quit\", \"stop\", \"done\", \"terminate\"):\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file=\"CONFIG_LIST.json\"\n",
    "gemini_filter_dict = {\"model\": [\"gemini\"]}\n",
    "gemini_config_list = autogen.config_list_from_json(\n",
    "    env_or_file=config_file, filter_dict=gemini_filter_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"retrieve_content\",\n",
    "            \"description\": \"retrieve content for code generation and question answering.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"message\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Refined message which keeps the original meaning and can be used to retrieve content for code generation and question answering.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"message\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"config_list\": gemini_config_list,\n",
    "    \"timeout\": 120,\n",
    "    \"seed\": 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_llm_config = {\n",
    "    \"config_list\": gemini_config_list,\n",
    "    \"timeout\": 120,\n",
    "    \"seed\": 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programmer_prompt = \"\"\n",
    "with open(\"prompts/Programmer.txt\") as f:\n",
    "    programmer_prompt = f.read()\n",
    "programmer_prompt += \"\"\"\\nRemember, You are a senior python engineer.you will get product specification and will create appropriate code to develop the requiered product.\n",
    "                        you should listen to the Code_Reviewer suggestions and improve you code if needed until there are no more fixes,\n",
    "                        Code_Reviewer suggestions are marked under `SUGGESTION`. each of your response should include the full fixed code.\n",
    "                        you also can use the retrieve_content function for extra matirial to solve your tasks,\n",
    "                        the retrieve_content function have retrival power to relevent books libraries\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_prompt = \"\"\n",
    "with open(\"prompts/Code_Reviewer.txt\") as f:\n",
    "    reviewer_prompt = f.read()\n",
    "reviewer_prompt += \"\"\"\\n Remember, You are a code reviewer. you need to review code sections from the Senior_Python_Engineer that marked under `REVIEW` and provide suggestions and fixes.\n",
    "                    mark your suggestions under `SUGGESTION`. Reply `DONE` when there are no more suggestions and fixes.\n",
    "                    you also can use the retrieve_content function for extra matirial to solve your tasks,\n",
    "                    the retrieve_content function have retrival power to relevent books libraries\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_prompt = \"\"\n",
    "with open(\"prompts/PM.txt\") as f:\n",
    "    pm_prompt = f.read()\n",
    "pm_prompt += \"\"\"\\nRemember, You are a product manager. you need to provide detailed full-stack web application description and specification.\n",
    "                        When Code_Reviewer send message marked under `DONE`, Reply `TERMINATE` and end the conversation.\n",
    "                        you should not replay on other messages.\n",
    "                        you also can use the retrieve_content function for extra matirial to solve your tasks,\n",
    "                        the retrieve_content function have retrival power to relevent books libraries\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragassistant = RetrieveUserProxyAgent(\n",
    "    name=\"Rag_Assistant\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"\"\"Assistant who has extra content retrieval power for solving difficult problems.\"\"\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    retrieve_config={\n",
    "        \"task\": \"qa\",\n",
    "        \"docs_path\": \"rag/\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder = RetrieveAssistantAgent(\n",
    "    name=\"Senior_Python_Engineer\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=programmer_prompt,\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = RetrieveAssistantAgent(\n",
    "    name=\"Product_Manager\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=pm_prompt,\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer = RetrieveAssistantAgent(\n",
    "    name=\"Code_Reviewer\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=reviewer_prompt,\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_content(message, n_results=3):\n",
    "        ragassistant.n_results = n_results  # Set the number of results to be retrieved.\n",
    "        # Check if we need to update the context.\n",
    "        update_context_case1, update_context_case2 = ragassistant._check_update_context(message)\n",
    "        if (update_context_case1 or update_context_case2) and ragassistant.update_context:\n",
    "            ragassistant.problem = message if not hasattr(ragassistant, \"problem\") else ragassistant.problem\n",
    "            _, ret_msg = ragassistant._generate_retrieve_user_reply(message)\n",
    "        else:\n",
    "            ret_msg = ragassistant.generate_init_message(message, n_results=n_results)\n",
    "        return ret_msg if ret_msg else message\n",
    "\n",
    "for agent in [pm, coder, reviewer]:\n",
    "    # register functions for all agents.\n",
    "    agent.register_function(\n",
    "        function_map={\n",
    "            \"retrieve_content\": retrieve_content,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(\n",
    "    agents=[pm, coder, reviewer], messages=[], max_round=12,speaker_selection_method=\"round_robin\"\n",
    ")\n",
    "coordinator = autogen.GroupChatManager(groupchat=groupchat, llm_config=manager_llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start chatting with the boss as this is the user proxy agent.\n",
    "coordinator.initiate_chat(\n",
    "    coordinator,\n",
    "    message=\"Create notification service, using python, which will load data from some db and will schedule nofitication base on the loaded records. the logic implementation is not defined so create only the abstractions for the class. eventually, give one example implementation for which will read from csv and schedule email notification base on the data metioned inside each record.\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
